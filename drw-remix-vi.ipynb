{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-13T20:01:17.412755Z",
     "iopub.status.busy": "2025-06-13T20:01:17.412394Z",
     "iopub.status.idle": "2025-06-13T20:01:20.987121Z",
     "shell.execute_reply": "2025-06-13T20:01:20.986054Z",
     "shell.execute_reply.started": "2025-06-13T20:01:17.41272Z"
    },
    "papermill": {
     "duration": 1.796887,
     "end_time": "2025-06-09T18:37:41.971663",
     "exception": false,
     "start_time": "2025-06-09T18:37:40.174776",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T20:01:20.989411Z",
     "iopub.status.busy": "2025-06-13T20:01:20.988883Z",
     "iopub.status.idle": "2025-06-13T20:01:32.294873Z",
     "shell.execute_reply": "2025-06-13T20:01:32.294117Z",
     "shell.execute_reply.started": "2025-06-13T20:01:20.989382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import pearsonr\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T20:01:32.2965Z",
     "iopub.status.busy": "2025-06-13T20:01:32.295733Z",
     "iopub.status.idle": "2025-06-13T20:01:32.309429Z",
     "shell.execute_reply": "2025-06-13T20:01:32.308228Z",
     "shell.execute_reply.started": "2025-06-13T20:01:32.296468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    TRAIN_PATH       = \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n",
    "    TEST_PATH        = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n",
    "    SUBMISSION_PATH  = \"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n",
    "    \n",
    "    BASE_FEATURES = [ # Renamed from FEATURES\n",
    "    \"X863\", \"X856\", \"X344\", \"X598\", \"X862\", \"X385\", \"X852\", \"X603\", \"X860\", \"X674\",\n",
    "    \"X415\", \"X345\", \"X137\", \"X855\", \"X174\", \"X302\", \"X178\", \"X532\", \"X168\", \"X612\",\n",
    "    \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\",\"X888\", \"X421\", \"X333\"\n",
    "    ]\n",
    "    NEW_FEATURES = [] # To be populated by engineered features\n",
    "    FEATURES = [] # Will be BASE_FEATURES + NEW_FEATURES\n",
    "    \n",
    "    \n",
    "    LABEL_COLUMN     = \"label\"\n",
    "    N_FOLDS          = 3\n",
    "    RANDOM_STATE     = 42\n",
    "    OPTUNA_N_TRIALS_XGB = 50 # Number of Optuna trials for XGBoost\n",
    "    OPTUNA_N_TRIALS_LGBM = 50 # Number of Optuna trials for LightGBM\n",
    "\n",
    "# Hyperparameters for XGBoost and LightGBM\n",
    "XGB_PARAMS = { # These will be overridden by Optuna, but can serve as a fallback or initial guess\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"device\": \"gpu\",\n",
    "    \"random_state\": Config.RANDOM_STATE,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": 0,\n",
    "}\n",
    "\n",
    "LGBM_PARAMS = { # These will be overridden by Optuna\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": Config.RANDOM_STATE,\n",
    "}\n",
    "\n",
    "LEARNERS = [\n",
    "    {\"name\": \"xgb\",  \"Estimator\": XGBRegressor,  \"params\": XGB_PARAMS},\n",
    "    {\"name\": \"lgbm\", \"Estimator\": LGBMRegressor, \"params\": LGBM_PARAMS} \n",
    "]\n",
    "\n",
    "MODEL_SLICES = [\n",
    "    {\"name\": \"full_data\",   \"cutoff\": 0},\n",
    "    {\"name\": \"last_75pct\",  \"cutoff\": 0},  \n",
    "    {\"name\": \"last_50pct\",  \"cutoff\": 0}\n",
    "]\n",
    "\n",
    "\n",
    "def create_time_decay_weights(n: int, decay: float = 0.95) -> np.ndarray:\n",
    "    positions = np.arange(n)\n",
    "    normalized = positions / float(n - 1)\n",
    "    weights = decay ** (1.0 - normalized)\n",
    "    return weights * n / weights.sum()\n",
    "\n",
    "def _add_engineered_features(df):\n",
    "    df_eng = df.copy()\n",
    "    epsilon = 1e-6 # To avoid division by zero\n",
    "\n",
    "    df_eng['bid_ask_qty_ratio'] = df_eng['bid_qty'] / (df_eng['ask_qty'] + epsilon)\n",
    "    df_eng['buy_sell_qty_ratio'] = df_eng['buy_qty'] / (df_eng['sell_qty'] + epsilon)\n",
    "    df_eng['qty_imbalance'] = (df_eng['bid_qty'] - df_eng['ask_qty']) - (df_eng['buy_qty'] - df_eng['sell_qty'])\n",
    "    df_eng['vol_x_bid_qty'] = df_eng['volume'] * df_eng['bid_qty']\n",
    "    df_eng['vol_x_ask_qty'] = df_eng['volume'] * df_eng['ask_qty']\n",
    "    \n",
    "    # Add more features here if needed\n",
    "    \n",
    "    # Update Config.NEW_FEATURES with the names of the new columns\n",
    "    new_feature_names = [col for col in df_eng.columns if col not in df.columns]\n",
    "    Config.NEW_FEATURES = new_feature_names\n",
    "    return df_eng\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_parquet(\n",
    "        Config.TRAIN_PATH,\n",
    "        columns=Config.BASE_FEATURES + [Config.LABEL_COLUMN]\n",
    "    ).reset_index(drop=True)\n",
    "    test_df = pd.read_parquet(\n",
    "        Config.TEST_PATH,\n",
    "        columns=Config.BASE_FEATURES\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Add engineered features\n",
    "    train_df = _add_engineered_features(train_df)\n",
    "    test_df = _add_engineered_features(test_df)\n",
    "\n",
    "    # Update the main FEATURES list in Config\n",
    "    Config.FEATURES = Config.BASE_FEATURES + Config.NEW_FEATURES\n",
    "    \n",
    "    submission_df = pd.read_csv(Config.SUBMISSION_PATH)\n",
    "    print(f\"Loaded train: {train_df.shape}, test: {test_df.shape}, submission: {submission_df.shape}\")\n",
    "    return train_df, test_df, submission_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T20:03:35.558129Z",
     "iopub.status.busy": "2025-06-13T20:03:35.557843Z",
     "iopub.status.idle": "2025-06-13T20:05:00.933671Z",
     "shell.execute_reply": "2025-06-13T20:05:00.932907Z",
     "shell.execute_reply.started": "2025-06-13T20:03:35.558109Z"
    },
    "papermill": {
     "duration": 732.497182,
     "end_time": "2025-06-09T18:49:54.470683",
     "exception": false,
     "start_time": "2025-06-09T18:37:41.973501",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# MAIN\n",
    "############################\n",
    "\n",
    "train_df, test_df, submission_df = load_data()\n",
    "n_samples = len(train_df)\n",
    "# set slice cutoffs\n",
    "MODEL_SLICES[1][\"cutoff\"] = int(0.25 * n_samples)\n",
    "MODEL_SLICES[2][\"cutoff\"] = int(0.50 * n_samples)\n",
    "\n",
    "# prepare storage for OOF and test preds\n",
    "oof_preds = {\n",
    "    learner[\"name\"]: {sl[\"name\"]: np.zeros(n_samples) for sl in MODEL_SLICES}\n",
    "    for learner in LEARNERS\n",
    "}\n",
    "test_preds = {\n",
    "    learner[\"name\"]: {sl[\"name\"]: np.zeros(len(test_df)) for sl in MODEL_SLICES}\n",
    "    for learner in LEARNERS\n",
    "}\n",
    "\n",
    "full_weights = create_time_decay_weights(n_samples)\n",
    "kf = KFold(n_splits=Config.N_FOLDS, shuffle=False)\n",
    "\n",
    "# cross-validation\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(train_df), start=1):\n",
    "    print(f\"\\n--- Fold {fold}/{Config.N_FOLDS} ---\")\n",
    "    X_valid_fold = train_df.iloc[valid_idx][Config.FEATURES]\n",
    "    y_valid_fold = train_df.iloc[valid_idx][Config.LABEL_COLUMN]\n",
    "\n",
    "    for sl in MODEL_SLICES:\n",
    "        slice_name = sl[\"name\"]\n",
    "        cutoff     = sl[\"cutoff\"]\n",
    "        subset     = train_df.iloc[cutoff:].reset_index(drop=True)\n",
    "        rel_idx    = train_idx[train_idx >= cutoff] - cutoff\n",
    "        print(f\"model setup {slice_name}\")\n",
    "        X_train_slice = subset.iloc[rel_idx][Config.FEATURES]\n",
    "        y_train_slice = subset.iloc[rel_idx][Config.LABEL_COLUMN]\n",
    "\n",
    "        # sample weights\n",
    "        if cutoff == 0:\n",
    "            sw_slice = full_weights[train_idx]\n",
    "        else:\n",
    "            sw_total = create_time_decay_weights(len(subset))\n",
    "            sw_slice = sw_total[rel_idx]\n",
    "\n",
    "        for learner in LEARNERS:\n",
    "            name      = learner[\"name\"]\n",
    "            Estimator = learner[\"Estimator\"]\n",
    "            base_params = learner[\"params\"].copy()\n",
    "\n",
    "            def objective(trial):\n",
    "                if name == \"xgb\":\n",
    "                    params = {\n",
    "                        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "                        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "                        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "                        **base_params\n",
    "                    }\n",
    "                    model = Estimator(**params)\n",
    "                    model.fit(X_train_slice, y_train_slice, sample_weight=sw_slice,\n",
    "                              eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                              early_stopping_rounds=50, verbose=False)\n",
    "                elif name == \"lgbm\":\n",
    "                    params = {\n",
    "                        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "                        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "                        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "                        **base_params\n",
    "                    }\n",
    "                    model = Estimator(**params)\n",
    "                    model.fit(X_train_slice, y_train_slice, sample_weight=sw_slice,\n",
    "                              eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                              callbacks=[LightGBMPruningCallback(trial, 'l1'), \n",
    "                                         lgb.early_stopping(stopping_rounds=50, verbose=-1)])\n",
    "                \n",
    "                preds = model.predict(X_valid_fold)\n",
    "                score, _ = pearsonr(y_valid_fold, preds)\n",
    "                return score\n",
    "\n",
    "            study_name = f\"{name}_{slice_name}_fold{fold}\"\n",
    "            study = optuna.create_study(direction='maximize', study_name=study_name, load_if_exists=True)\n",
    "            n_trials = Config.OPTUNA_N_TRIALS_XGB if name == \"xgb\" else Config.OPTUNA_N_TRIALS_LGBM\n",
    "            study.optimize(objective, n_trials=n_trials, n_jobs=1) # n_jobs=1 for GPU, can be -1 for CPU\n",
    "            \n",
    "            print(f\"Best params for {name} on {slice_name} fold {fold}: {study.best_params}\")\n",
    "            best_params_for_model = {**base_params, **study.best_params}\n",
    "            model = Estimator(**best_params_for_model)\n",
    "\n",
    "            # Re-fit with best params on the full training data for this slice and fold\n",
    "            # For XGBoost, we need to handle early stopping differently or remove it for final fit\n",
    "            if name==\"xgb\":\n",
    "                # For XGB, fit on X_train_slice, y_train_slice. Early stopping was for param search.\n",
    "                # You might want to adjust n_estimators based on Optuna's findings or use a fixed large number and rely on early stopping during Optuna.\n",
    "                # For simplicity here, we use the n_estimators found by Optuna.\n",
    "                model.fit(X_train_slice, y_train_slice, sample_weight=sw_slice, verbose=False) \n",
    "            else: # For LGBM\n",
    "                model.fit(X_train_slice, y_train_slice, sample_weight=sw_slice, \n",
    "                          eval_set=[(X_valid_fold, y_valid_fold)], # Can keep eval_set for potential internal use by LGBM, but not for early stopping here\n",
    "                          callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=-1)] # Re-add early stopping for the final fit on this fold's data\n",
    "                         )\n",
    "\n",
    "            # OOF predictions\n",
    "            mask = valid_idx >= cutoff\n",
    "            if mask.any():\n",
    "                idxs = valid_idx[mask]\n",
    "                oof_preds[name][slice_name][idxs] = model.predict(\n",
    "                    train_df.iloc[idxs][Config.FEATURES])\n",
    "            if cutoff > 0 and (~mask).any():\n",
    "                oof_preds[name][slice_name][valid_idx[~mask]] = (\n",
    "                    oof_preds[name][\"full_data\"][valid_idx[~mask]])\n",
    "\n",
    "            # test predictions\n",
    "            test_preds[name][slice_name] += model.predict(test_df[Config.FEATURES]) / Config.N_FOLDS # Averaging here as Optuna runs per fold\n",
    "\n",
    "# Note: Test predictions were previously averaged outside the loop. \n",
    "# With Optuna finding best params per fold, it's more common to average predictions from each fold's best model.\n",
    "# The division by N_FOLDS for test_preds is now inside the learner loop.\n",
    "\n",
    "# compute Pearson scores per learner and slice\n",
    "pearson_scores = {\n",
    "    name: {slice_name: pearsonr(train_df[Config.LABEL_COLUMN], preds)[0]\n",
    "           for slice_name, preds in slices.items()}\n",
    "    for name, slices in oof_preds.items()\n",
    "}\n",
    "print(\"\\nPearson scores by learner and slice:\")\n",
    "print(pearson_scores)\n",
    "\n",
    "# -- Ensemble per learner across slices --\n",
    "learner_ensembles = {}\n",
    "for learner_name, slice_scores in pearson_scores.items():\n",
    "    # simple ensemble\n",
    "    oof_simple = np.mean(list(oof_preds[learner_name].values()), axis=0)\n",
    "    test_simple_list = [test_preds[learner_name][sn] for sn in MODEL_SLICES_NAMES] # Assuming MODEL_SLICES_NAMES is defined or use list(test_preds[learner_name].keys())\n",
    "    # Need to ensure MODEL_SLICES_NAMES is defined, e.g., MODEL_SLICES_NAMES = [s['name'] for s in MODEL_SLICES]\n",
    "    MODEL_SLICES_NAMES = [s['name'] for s in MODEL_SLICES] # Define it here for clarity\n",
    "    test_simple = np.mean([test_preds[learner_name][sn] for sn in MODEL_SLICES_NAMES], axis=0)\n",
    "    score_simple = pearsonr(train_df[Config.LABEL_COLUMN], oof_simple)[0]\n",
    "\n",
    "    # weighted ensemble\n",
    "    total_score = sum(slice_scores.values())\n",
    "    slice_weights = {sn: sc/total_score if total_score else 1/len(slice_scores) for sn, sc in slice_scores.items()} # handle total_score = 0\n",
    "    oof_weighted = sum(slice_weights[sn] * oof_preds[learner_name][sn]\n",
    "                       for sn in slice_weights)\n",
    "    test_weighted = sum(slice_weights[sn] * test_preds[learner_name][sn]\n",
    "                        for sn in slice_weights)\n",
    "    score_weighted = pearsonr(train_df[Config.LABEL_COLUMN], oof_weighted)[0]\n",
    "\n",
    "    print(f\"\\n{learner_name.upper()} Simple ensemble Pearson:   {score_simple:.4f}\")\n",
    "    print(f\"\\n{learner_name.upper()} Weighted ensemble Pearson: {score_weighted:.4f}\")\n",
    "\n",
    "    learner_ensembles[learner_name] = {\n",
    "        \"oof_simple\": oof_simple,\n",
    "        \"test_simple\": test_simple # Storing the simple average of test predictions across slices for this learner\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T20:05:04.391595Z",
     "iopub.status.busy": "2025-06-13T20:05:04.391294Z",
     "iopub.status.idle": "2025-06-13T20:05:05.657331Z",
     "shell.execute_reply": "2025-06-13T20:05:05.656395Z",
     "shell.execute_reply.started": "2025-06-13T20:05:04.391575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -- Final ensemble across learners (simple) --\n",
    "final_oof = np.mean([le[\"oof_simple\"] for le in learner_ensembles.values()], axis=0)\n",
    "final_test = np.mean([le[\"test_simple\"] for le in learner_ensembles.values()], axis=0)\n",
    "final_score = pearsonr(train_df[Config.LABEL_COLUMN], final_oof)[0]\n",
    "print(f\"\\nFINAL ensemble across learners Pearson: {final_score:.4f}\")\n",
    "\n",
    "# save submission\n",
    "submission_df[\"prediction\"] = final_test\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Wrote submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11418275,
     "sourceId": 96164,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 741.062359,
   "end_time": "2025-06-09T18:49:56.179877",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T18:37:35.117518",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
